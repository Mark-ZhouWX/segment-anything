#---------------------------------------------
# Part 1: system basic config setting
distributed: False
device: cuda
work_root: &work_root ./work_dir/
log_level: info
log_interval: 20
save_interval: 2

# ---------------------------------------------
# Part2: module setting
loss_manager:
#  type: fixed  # dynamic or
#  scale_sense: 1024
  loss_scaler:
    type: dynamic
  grad_clip: False
  drop_overflow_update: False

optimizer:
  type: segment_anything.optim.optimizer.AdamW
  weight_decay: 1e-4
  group_param:

  lr_scheduler:
    type: segment_anything.optim.scheduler.SAMDynamicDecayLR
    learning_rate: 8e-6
    warmup_steps: 250
    decay_steps: [ 60000, 86666 ]
    decay_factor: 10


network:
  model:
    type: vit_b
    checkpoint: ./models/sam_vit_b_01ec64.pth
    freeze:
      image_encoder: True
      prompt_encoder: True

  loss:
    type: segment_anything.modeling.loss.SAMLoss


train_loader:
  dataset:
    type: segment_anything.dataset.dataset.COCODataset
    data_dir: ./datasets/coco2017/train2017
    annotation_path: ./datasets/coco2017/annotations/instances_train2017.json
    transform_pipeline:
      - type: segment_anything.dataset.transform.ImageResizeAndPad
        target_size: 1024
      - type: segment_anything.dataset.transform.ImageNorm
        hwc2chw: True
    output_column: ['image', 'masks', 'boxes']

  model_column: ['image', 'boxes']  # columns for model cell input
  loss_column:  ['masks', 'valid_boxes']  # columns for loss function input

  shuffle: True
  batch_size: 1
  epoch_size: 20
  drop_remainder: True
  num_workers: 2
  max_rowsize: 24  # 24M space for dataloader


eval_loader: &eval_loader
  dataset:
    type: segment_anything.dataset.dataset.COCODataset
    data_dir: ./datasets/coco2017/val2017
    annotation_path: ./datasets/coco2017/annotations/instances_val2017.json
    transform_pipeline:
      - type: segment_anything.dataset.transform.ImageResizeAndPad
        target_size: 1024
      - type: segment_anything.dataset.transform.ImageNorm
        hwc2chw: True
    output_column: ['image', 'masks', 'boxes', 'valid_boxes', 'origin_hw']

  model_column: &model_column [ 'image', 'boxes' ]  # columns for model cell input
  eval_column: &eval_column [ 'masks', 'valid_boxes', 'origin_hw']  # columns for evaluation, usually for metric calculation or visualization

  shuffle: True
  batch_size: 1
  drop_remainder: False
  num_workers: 1
  max_rowsize: 36  # 36M space for dataloader, increase with gt_size
  max_eval_iter: null  # the max iteration to eval, default to eval all the dataset

